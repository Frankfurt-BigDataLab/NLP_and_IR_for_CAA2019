{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "developed by Antje Loyal, \n",
    "modified by Sebastian Gampe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from os import listdir\n",
    "from os.path import isfile, join, splitext, basename\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Make sure that caffe is on the python path: \n",
    "CAFFE_ROOT = '/home/cnt/caffe-master/python'        # CHANGE THIS LINE TO YOUR Caffe PATH\n",
    "sys.path.insert(0, CAFFE_ROOT + 'python')\n",
    "import caffe\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU or CPU\n",
    "#caffe.set_mode_cpu()\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "args = sys.argv\n",
    "PRETRAINED = \"\"\n",
    "MODEL_FILE = \"\"\n",
    "mean = \"\"\n",
    "testDir = \"\"\n",
    "labelstxt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direcory of the used model\n",
    "modelDir = \"/home/cnt/model/\"\n",
    "\n",
    "# get the necessary model and net files\n",
    "files = [f for f in listdir(modelDir) if isfile(join(modelDir, f))]\n",
    "for t in files:\n",
    "    if t.endswith(\".caffemodel\"):\n",
    "        PRETRAINED = modelDir + t\n",
    "    if t.endswith(\"deploy.prototxt\"):\n",
    "        MODEL_FILE = modelDir + t\n",
    "    if t.endswith(\".binaryproto\"):\n",
    "        meanproto = modelDir + t\n",
    "    if t.endswith(\"labels.txt\"):\n",
    "        labelstxt = modelDir + t\n",
    "\n",
    "\n",
    "# target directory with image to process and ground truth (Portraits) \n",
    "testFile = \"/home/cnt/data/test.jpg\"\n",
    "groundTruth = \"augustus\"\n",
    "\n",
    "# Set path to dircectory with set of images to process (Portraits)\n",
    "#testDir = \"/home/cnt/students/ML/Daten/OCREPortraits/\"\n",
    "#testDir = \"/home/cnt/students/ML/Daten/OCRETrainedClasses/\"\n",
    "testDir = \"/home/cnt/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating list of all labels\n",
    "labelsO = open(labelstxt,'r').read().split('\\n')\n",
    "labels = []\n",
    "for lab in labelsO:\n",
    "    labels.append(lab.replace(\" \",\"_\"))\n",
    "#labels.replace(\" \",\"_\")\n",
    "if '' in labels:\n",
    "    del labels[(labels.index(''))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert .binaryproto to .npy\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( meanproto , 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array(caffe.io.blobproto_to_array(blob) )\n",
    "out = arr[0]\n",
    "np.save( modelDir + \"mean.npy\" , out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the file name and puts together the matching OCRE ID\n",
    "def getIDFile(image):\n",
    "    #clear_name = basename(clear_name)\n",
    "    ocre_id = os.path.splitext(os.path.basename(str(image)))[0]\n",
    "    ocre_id = \"http://numismatics.org/ocre/id/\" + ocre_id\n",
    "    return ocre_id\n",
    "\n",
    "# Gets the folder name and puts together the matching OCRE ID\n",
    "def getIDFolder(image):\n",
    "    ocre_id = os.path.dirname(str(image))\n",
    "    ocre_id = os.path.basename(os.path.normpath(ocre_id))\n",
    "    ocre_id = \"http://numismatics.org/ocre/id/\" + ocre_id\n",
    "    return ocre_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process one image\n",
    "def processImage(image):\n",
    "    # loading neural net with trained weights\n",
    "    net = caffe.Net(MODEL_FILE, PRETRAINED, caffe.TEST)    \n",
    "    in_shape = net.blobs['data'].data.shape    \n",
    "    # reshaping data layer to process #images in one batch (bs) (with 3 colors (RGB) and size 244x244)\n",
    "    net.blobs['data'].reshape(1, 3, 224, 224)\n",
    "    net.reshape()\n",
    "    # Set the shape of the input for the transformer\n",
    "    transformer = caffe.io.Transformer({'data': in_shape})\n",
    "    # set mean from given mean file (previous converted from the .binaryproto)\n",
    "    transformer.set_mean('data', np.load(modelDir + 'mean.npy').mean(1).mean(1))\n",
    "    # order of color channels\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    # RGB to BGR\n",
    "    transformer.set_channel_swap('data', (2,1,0))\n",
    "    img = Image.open(image)\n",
    "    # scale all images to 224x224 (VGG16) or 227x227 (AlexNet)\n",
    "    img = img.resize((224,224), Image.ANTIALIAS)\n",
    "    #img = img.resize((227,227), Image.ANTIALIAS)\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    # Transform the image depending of data layer definition and transformer settings from above\n",
    "    transformed_image = transformer.preprocess('data', img)\n",
    "    net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "    # Forward pass of the images through the network\n",
    "    out = net.forward()\n",
    "    maxClass = labels[out['softmax'][0].argmax()]   \n",
    "    #print(\"For picture \" + str(image) + \" the net predicts: \" + str(maxClass) + \" and ground truth is: \" + groundTruth)\n",
    "    ocre_id = getIDFolder(image)\n",
    "    \n",
    "    # GRAD-CAM implementation\n",
    "    # Source: https://github.com/gautamMalu/caffe-gradCAM/blob/master/00-classification-gradCAM-Visualization.ipynb\n",
    "    \n",
    "    output_prob = out['softmax'][0]\n",
    "    print ('predicted class is:', output_prob.argmax())\n",
    "\n",
    "    label_index = output_prob.argmax()\n",
    "    caffeLabel = np.zeros((1,69))\n",
    "    caffeLabel[0,label_index] = 1;\n",
    "  \n",
    "    vis_layer = 'pool5' # visualization layer\n",
    "    \n",
    "    grads=net.backward(diffs=[vis_layer],**{'softmax':caffeLabel})\n",
    "    #bw=net.backward(diffs=[vis_layer],**{net.outputs[0]: caffeLabel})\n",
    "    vis_grad= grads['pool5'] # gradients of pool5 layer with respect to output class\n",
    "    vis_grad = np.squeeze(vis_grad) # removing the extra dimension\n",
    "    mean_grads = np.mean(vis_grad, axis=(1, 2)) # mean of gradients\n",
    "\n",
    "\n",
    "    activations = net.blobs[vis_layer].data\n",
    "    activations = np.squeeze(activations)\n",
    "    n_nodes = activations.shape[0] # number of nodes\n",
    "    vis_size = activations.shape[1:] #visualization shape\n",
    "    vis = np.zeros((7, 7), dtype=np.float32) \n",
    "\n",
    "\n",
    "    #generating saliency image\n",
    "    for i in range(n_nodes):\n",
    "        activation = activations[i, :, :]\n",
    "        weight = mean_grads[i]\n",
    "        weighted_activation = activation*weight\n",
    "        vis += weighted_activation\n",
    "\n",
    "\n",
    "    # We select only those activation which has positively contributed in prediction of given class\n",
    "    vis = np.maximum(vis, 0)   # relu\n",
    "    vis_img = Image.fromarray(vis, None)\n",
    "    vis_img = vis_img.resize((224,224),Image.BICUBIC)\n",
    "    vis_img = vis_img / np.max(vis_img)\n",
    "    vis_img = Image.fromarray(np.uint8(cm.jet(vis_img) * 255))\n",
    "    vis_img = vis_img.convert('RGB') # dropping alpha channel\n",
    "    plt.imshow(vis_img)\n",
    "    #plt.show()\n",
    "    image_path = image\n",
    "    input_image = Image.open(image_path)\n",
    "    input_image = input_image.resize((224,224))\n",
    "    input_image = input_image.convert('RGB')\n",
    "\n",
    "    #print(vis_img.size, input_i)\n",
    "    heat_map = Image.blend(input_image, vis_img, 0.3)\n",
    "    plt.imshow(heat_map)\n",
    "    plt.axis('off')\n",
    "    #plt.show()\n",
    "    return (ocre_id, maxClass, heat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ocre_id, maxClass, image = processImage(testFile)\n",
    "image.save('/home/cnt/data/heatmaps/' + maxClass + '_grad.jpg')\n",
    "print(ocre_id + ' ' + maxClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List all image files (.jpg or .png or .tif) in subfolders of dir\n",
    "def list_files(dir):\n",
    "    r = []                                                                                                                                                                                                      \n",
    "    for dirpath, subdir, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if (file.endswith(\".jpg\")) or (file.endswith(\".png\")) or (file.endswith(\".tif\")): \n",
    "                r.append(os.path.join(dirpath, file))                                                                         \n",
    "    return r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class is: 14\n"
     ]
    }
   ],
   "source": [
    "# use single image mode to create heatmaps for all images in a certain directory\n",
    "testDirHeat = \"/home/cnt/data/augustus/\"\n",
    "save_path = '/home/cnt/data/heatmaps/01'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(path)    \n",
    "files = list_files(testDirHeat)\n",
    "for testFile in files:\n",
    "    ocre_id, maxClass, image = processImage(testFile)\n",
    "    pathWords = testFile.split('/')\n",
    "    image.save(path + maxClass + \"-\" + (pathWords[len(pathWords)-4].replace('.', '')) + \"-\" + (pathWords[len(pathWords)-3].replace('.', '')) + \"-\" + (pathWords[len(pathWords)-2].replace('.', '')) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained  model on images in single image mode and write the results to a pandas DataFrame \n",
    "result_dict = {}\n",
    "result_dict[\"DesignID\"] = []\n",
    "result_dict[\"Results\"] = []\n",
    "\n",
    "moreImages = list_files(testDir)\n",
    "for image in moreImages:\n",
    "    result = processImage(image)\n",
    "    result_dict[\"DesignID\"].append(result[0])\n",
    "    result_dict[\"Results\"].append(result[1])\n",
    "\n",
    "\n",
    "\n",
    "erg = pd.DataFrame({\"DesignID\" : result_dict[\"DesignID\"],\n",
    "                   \"y_predict\" : result_dict[\"Results\"]})\n",
    "\n",
    "erg.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
